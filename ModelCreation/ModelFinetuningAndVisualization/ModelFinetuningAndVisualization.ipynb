{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a9649a",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b83a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/kkonatha/kk/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling, AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f365a9bb",
   "metadata": {},
   "source": [
    "CODE TO CHECK IF THE GPU IS DETECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260c9317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: NVIDIA A100-SXM-80GB, n_gpu: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "#Get the GPU device name.\n",
    "device_name = torch.cuda.get_device_name()\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b10db",
   "metadata": {},
   "source": [
    "LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e761bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/kkonatha/.cache/huggingface/datasets/json/default-688fdf028d397096/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
      "100%|██████████| 1/1 [00:00<00:00, 513.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'URL': 'https://accure.ai/docs/momentum-user-guide/getting-started-with-momentum/1-getting-started-with-momentum/',\n",
       " 'Product_Title': 'Momentum',\n",
       " 'Section_Title': 'Getting Started with Momentum',\n",
       " 'Section_Num': 1,\n",
       " 'Article_Title': 'Accessing Momentum',\n",
       " 'Article_Num': 1,\n",
       " 'Article_Body': 'Momentum is a web-based system that is accessible via a web browser. To launch Momentum, point your browser address to: \\nhttp://<public-ip-or-domain>:8800/mv-admin \\nIf you installed Momentum from AWS marketplace, the default port to access Momentum is 8800. \\nThe above URL will launch the login page.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to train the model without a test set.\n",
    "momentum = load_dataset('json', data_files='MPM.json')\n",
    "#momentum = load_dataset('json', data_files='MPM_conditioned.json', split = 'train')\n",
    "#momentum = momentum.train_test_split(test_size=0.2)\n",
    "flattened_mpm = momentum.flatten()\n",
    "example = flattened_mpm[\"train\"][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e219f",
   "metadata": {},
   "source": [
    "TOKENIZE THE DATA AND ADD THE PAD TOKENS TO THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb736d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469ef83",
   "metadata": {},
   "source": [
    "PREPROCESS THE DATA WITH THE REQUIRED FIELDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40626b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"Article_Body\"]], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08e0c3",
   "metadata": {},
   "source": [
    "MAP THE TOKENIZED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2250e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kkonatha/.cache/huggingface/datasets/json/default-688fdf028d397096/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-29a5e2ba64eee4e9_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_mpm = flattened_mpm.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=momentum[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76ac4e",
   "metadata": {},
   "source": [
    "ENCODE THE DATA WITH THE FIXED BLOCK SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03582a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 60\n",
    "\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b19061",
   "metadata": {},
   "source": [
    "PREPROCESSED DATA FOR FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60bd30a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kkonatha/.cache/huggingface/datasets/json/default-688fdf028d397096/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-492df3d1432d8d5e_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "mpm_dataset = tokenized_mpm.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3ee7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1025\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8e146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "242493ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "mpm_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2391de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1024, None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the underlying PyTorch model\n",
    "model = mpm_model.transformer\n",
    "\n",
    "# Compute the expected sequence length from the model configuration\n",
    "seq_length = mpm_model.config.n_positions\n",
    "\n",
    "# Compute the expected input shape\n",
    "input_shape = (seq_length, None)\n",
    "\n",
    "print(\"Input shape:\", input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c818b43f",
   "metadata": {},
   "source": [
    "TRAINING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd71992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='445' max='30100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  445/30100 00:40 < 44:39, 11.07 it/s, Epoch 5.16/350]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.615300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.348100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.235800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.184200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.130300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gpt_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=7e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=350,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    per_device_train_batch_size=3,\n",
    "    #gradient_accumulation_steps=4,\n",
    "    save_steps=10_000,\n",
    "    evaluation_strategy='no',\n",
    "    #load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=mpm_model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=mpm_dataset['train'],\n",
    ")\n",
    "\n",
    "train_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d910874",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a68d50",
   "metadata": {},
   "source": [
    "SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded57ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpm_model.save_pretrained('/scratch/kkonatha/test8') #then need to load it to generate a test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38db7b2",
   "metadata": {},
   "source": [
    "PROMPT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc665d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/scratch/kkonatha/test8\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    \n",
    "prompt = (\"Momentum provides SQL-based interface for data transformation\"\n",
    "          \" Data cleaning, null removal, datatype conversion, column renaming, mathematical transformation, blending, merging, joining with multiple data sources are some of the transformation tasks that can be performed over data created within Momentum\")\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    attention_mask=attention_mask,\n",
    "    num_return_sequences=1,\n",
    "    #return_dict_in_generate=True,\n",
    "    temperature=0.3,\n",
    "    max_length=500,\n",
    ")\n",
    "\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c71047",
   "metadata": {},
   "source": [
    "VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85236de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_values = train_output.loss_history[\"training_loss\"]\n",
    "plt.plot(train_loss_values, label=\"Training loss\")\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 3) # Adjust the y-axis limits as needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b097f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSS CURVES\n",
    "\n",
    "train_output = trainer.train()\n",
    "train_loss_values = train_output.metrics['train_loss']\n",
    "plt.plot(train_loss_values, label=\"Training loss\")\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"training_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERPLEXITY SCORE AND CURVE\n",
    "train_loss = trainer.evaluate(mpm_dataset['train'])['eval_loss']\n",
    "train_perplexity = torch.exp(torch.tensor(train_loss))\n",
    "\n",
    "print(\"Train perplexity:\", train_perplexity.item())\n",
    "\n",
    "plt.plot(train_ppl, label='Training Perplexity')\n",
    "plt.plot(val_ppl, label='Validation Perplexity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENSION MAP\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from bertviz import head_view\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/scratch/kkonatha/test8\")\n",
    "\n",
    "# Define input text\n",
    "input_text = 'Momentum is a web-based system that is accessible via a web browser'\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Get model output and attention weights\n",
    "output = model(input_ids)\n",
    "attention = output['attentions']\n",
    "\n",
    "# Visualize attention map for a specific layer and head\n",
    "layer_id = 0  # layer id\n",
    "head_id = 0   # head id\n",
    "attention_map = attention[layer_id][0][head_id].detach().numpy()\n",
    "head_view(attention_map, input_tokens=tokenizer.convert_ids_to_tokens(input_ids[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk",
   "language": "python",
   "name": "kk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
